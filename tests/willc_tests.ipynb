{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 080420 verbosify apostrophes and plural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    if i == 6: break\n",
    "\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"I'm\", 'I am', 'ur boy is'}\n",
      "{'wassup'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(s) for s in [{\"I'm\", 'I am', 'ur boy is'}, {'wassup'}]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "\n",
    "# -- Helper functions for verbosify -- #\n",
    "WHITELIST = [['a', 'an', 'the'],\n",
    "             ['I', 'me', 'ur boy', 'me, myself and I', 'yours truly'],\n",
    "             ['you', 'thou', 'thoust'],\n",
    "             ['will', 'shall', 'shalt'],\n",
    "             [\"I'm\", 'I am', 'ur boy is'],\n",
    "             [\"can't\", 'cannot', 'unable', 'shant'],\n",
    "             [\"shouldn't\", 'shant', \"shalln't\"]]\n",
    "\n",
    "def get_word_list(input_sentence):\n",
    "    l = []\n",
    "    temp = [v for v in re.split('(\\W)', input_sentence) if v != '']\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(temp):\n",
    "        if temp[i] == \"'\" and i > 0 and i < len(temp)-1:\n",
    "            # check possessive\n",
    "            if temp[i+1] == 's': l.append(\"'s\")\n",
    "            # check contraction\n",
    "            elif temp[i-1] != ' ' and temp[i+1] != ' ':                \n",
    "                l[-1] += \"'\" + temp[i+1]\n",
    "            \n",
    "            i += 2\n",
    "        else:\n",
    "            l.append(temp[i])\n",
    "            i += 1\n",
    "    \n",
    "    return l\n",
    "            \n",
    "\n",
    "def get_synonym(word, pos):\n",
    "    synsets = wordnet.synsets(word)\n",
    "    synonyms = []\n",
    "\n",
    "    # loop through all synsets\n",
    "    for synset in synsets:\n",
    "        # don't check synset if wrong part of speech\n",
    "        if synset.name().split('.')[1] not in pos: continue\n",
    "\n",
    "        # loop through each synonym\n",
    "        for synonym in synset.lemmas():\n",
    "            synonym = synonym.name()\n",
    "            if synonym != word and synonym not in synonyms: synonyms.append(synonym)\n",
    "    \n",
    "    # no unique synonyms?\n",
    "    if not synsets or not synonyms: return word\n",
    "    # otherwise, choose random synonym\n",
    "    return random.choice(synonyms).replace('_', ' ')\n",
    "\n",
    "def get_whitelist_synonym(word):\n",
    "    # get the correct set\n",
    "    for synonyms in WHITELIST:\n",
    "        if word in synonyms: break\n",
    "\n",
    "    return random.choice(synonyms) # return random synonym\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'): return 'as'\n",
    "    elif treebank_tag.startswith('V'): return 'v'\n",
    "    elif treebank_tag.startswith('N'): return 'n'\n",
    "    elif treebank_tag.startswith('R'): return 'r'\n",
    "    else: return ''\n",
    "\n",
    "\n",
    "# -- main verbosify function -- #\n",
    "def verbosify(input_sentence):\n",
    "    new_sentence = ''\n",
    "\n",
    "    # go through every word\n",
    "    for word, pos in pos_tag(get_word_list(input_sentence)):\n",
    "        # punctuation/whitespace/possessive, 'I', whitelist, normal word\n",
    "        if re.match(r'[^\\w]', word) or word == \"'s\": new_sentence += word\n",
    "        elif word.upper() == 'I': new_sentence += get_whitelist_synonym('I')\n",
    "        elif any([word in s for s in WHITELIST]): new_sentence += get_whitelist_synonym(word)\n",
    "        else: new_sentence += get_synonym(word, get_wordnet_pos(pos))\n",
    "\n",
    "    # return the sentence\n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fundamentally, the utmost two time me equal downstairs for a stretch out stop of meter, yours truly experience a shrewd prick annoyance where the medicament embody give\n"
     ]
    }
   ],
   "source": [
    "print(verbosify(\"basically, the last two times i was downstairs for an extended period of time, i felt a sharp stinging pain where the medication was applied\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"you're\", 'RB'),\n",
       " ('sad', 'JJ'),\n",
       " ('about', 'IN'),\n",
       " ('the', 'DT'),\n",
       " (\"mechanics'\", 'NN'),\n",
       " ('cars', 'NNS')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag([\"you're\", 'sad', 'about', \"the\", \"mechanics\", 'cars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unable'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_synonym('unable', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
